{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMI9k0UVvKEWFe+is2lneHE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GodfreyAchu/Machine-Learning/blob/main/Cross_Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cross-validation**\n",
        "\n",
        "## **Hold-out cross-validation**\n",
        "\n",
        "Hold-out cross-validation is the simplest and most common technique.\n",
        "\n",
        "**The algorithm of hold-out technique:**\n",
        "\n",
        "Divide the dataset into two parts: the training set and the test set.\n",
        "Usually, 80% of the dataset goes to the training set and 20% to the test set but you may choose any splitting that suits you better.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CHul4idX0o_F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PWY3nSXf0HOD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = np.arange(10).reshape((5, 2)), range(5)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=111)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **K-Fold Cross Validation**\n",
        "is a technique that minimizes the disadvantages of the hold-out method. k-Fold introduces a new way of splitting the dataset which helps to overcome the “test only once bottleneck”."
      ],
      "metadata": {
        "id": "Cl356giv1XtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
        "y = np.array([1, 2, 3, 4])\n",
        "kf = KFold(n_splits=2)\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pqy01PVN1bmK",
        "outputId": "a7429a0a-4141-42b2-d1f4-a57bb26e51eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [2 3] TEST: [0 1]\n",
            "TRAIN: [0 1] TEST: [2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Leave-one-out cross-validation**\n",
        "\n",
        "Leave-one-out сross-validation (LOOCV) is an extreme case of k-Fold CV. Imagine if k is equal to n where n is the number of samples in the dataset. Such k-Fold case is equivalent to Leave-one-out technique."
      ],
      "metadata": {
        "id": "HgJb3sZG1hf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "X = np.array([[1, 2], [3, 4]])\n",
        "y = np.array([1, 2])\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "for train_index, test_index in loo.split(X):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPko6jhP1iYw",
        "outputId": "3ea0bc85-ffff-4e7e-8cd7-97d41ccb438f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [1] TEST: [0]\n",
            "TRAIN: [0] TEST: [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
        "y = np.array([1, 2, 3, 4])\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "for train_index, test_index in loo.split(X):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JAjmS1y1o0W",
        "outputId": "e857c185-d27c-41cd-8eac-ca5839065da3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [1 2 3] TEST: [0]\n",
            "TRAIN: [0 2 3] TEST: [1]\n",
            "TRAIN: [0 1 3] TEST: [2]\n",
            "TRAIN: [0 1 2] TEST: [3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Leave-p-out cross-validation**\n",
        "\n",
        "Leave-p-out cross-validation (LpOC) is similar to Leave-one-out CV as it creates all the possible training and test sets by using p samples as the test set.\n",
        "\n",
        "Still, it is worth mentioning that unlike LOOCV and k-Fold test sets will overlap for LpOC if p is higher than 1."
      ],
      "metadata": {
        "id": "1SrhHxlA102Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import LeavePOut\n",
        "\n",
        "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
        "y = np.array([1, 2, 3, 4])\n",
        "lpo = LeavePOut(2)\n",
        "\n",
        "for train_index, test_index in lpo.split(X):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZQqKf4a13Bn",
        "outputId": "dc4de6ec-cc33-45fd-af3e-579abc2a73e5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [2 3] TEST: [0 1]\n",
            "TRAIN: [1 3] TEST: [0 2]\n",
            "TRAIN: [1 2] TEST: [0 3]\n",
            "TRAIN: [0 3] TEST: [1 2]\n",
            "TRAIN: [0 2] TEST: [1 3]\n",
            "TRAIN: [0 1] TEST: [2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Stratified k-Fold**\n",
        "\n",
        "Stratified k-Fold is a variation of the standard k-Fold CV technique which is designed to be effective in such cases of target imbalance."
      ],
      "metadata": {
        "id": "pLI-oy4Y1_uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
        "y = np.array([0, 0, 1, 1])\n",
        "skf = StratifiedKFold(n_splits=2)\n",
        "\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un6Lf9c02BJS",
        "outputId": "42179af7-073a-48c9-9e57-c4ab9bc5691b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [1 3] TEST: [0 2]\n",
            "TRAIN: [0 2] TEST: [1 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [5, 6], [5, 6]])\n",
        "y = np.array([0, 0, 1, 1, 2 , 2])\n",
        "skf = StratifiedKFold(n_splits=2)\n",
        "\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfjFld1q2EdI",
        "outputId": "be48b45b-aae9-48db-d3d8-ac4bf7014ce7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [1 3 5] TEST: [0 2 4]\n",
            "TRAIN: [0 2 4] TEST: [1 3 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Repeated k-Fold cross-validation**\n",
        "\n",
        "Repeated k-Fold cross-validation or Repeated random sub-sampling CV is probably the most robust of all CV techniques in this paper. It is a variation of k-Fold but in the case of Repeated k-Folds k is not the number of folds. It is the number of times we will train the model."
      ],
      "metadata": {
        "id": "OA1MbCVE2LbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "\n",
        "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
        "y = np.array([0, 0, 1, 1])\n",
        "rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=42)\n",
        "\n",
        "for train_index, test_index in rkf.split(X):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVOtBUhu2NNz",
        "outputId": "d6c1e36e-a7f3-4e7d-930b-8fe24ffab1f9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [0 2] TEST: [1 3]\n",
            "TRAIN: [1 3] TEST: [0 2]\n",
            "TRAIN: [0 2] TEST: [1 3]\n",
            "TRAIN: [1 3] TEST: [0 2]\n"
          ]
        }
      ]
    }
  ]
}